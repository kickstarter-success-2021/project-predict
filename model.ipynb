{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0849be1930e84a28de76efd7f21d926cca918e7072377246a7749ae7f6697b53e",
   "display_name": "Python 3.8.5 64-bit ('KickstarterSuccess-Diw2u4NI': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import pickle\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  backers_count    category    goal  pledged  spotlight  state  \\\n",
       "0        3692            128  publishing  4250.0   4718.0          1      1   \n",
       "1        3721              0  publishing  5000.0      0.0          0      0   \n",
       "2        3751              1  publishing  1500.0     25.0          0      0   \n",
       "3        3798              2  publishing  4000.0    120.0          0      0   \n",
       "4        3863              0  publishing    10.0      0.0          0      0   \n",
       "\n",
       "   blurb_length  goal_in_usd  campaign_duration sub_category  \n",
       "0          17.0      5770.03                 40        zines  \n",
       "1          22.0      3804.70                 30        zines  \n",
       "2          20.0      1705.15                 30        zines  \n",
       "3          19.0      5371.42                 60        zines  \n",
       "4          16.0         9.15                 30        zines  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>backers_count</th>\n      <th>category</th>\n      <th>goal</th>\n      <th>pledged</th>\n      <th>spotlight</th>\n      <th>state</th>\n      <th>blurb_length</th>\n      <th>goal_in_usd</th>\n      <th>campaign_duration</th>\n      <th>sub_category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3692</td>\n      <td>128</td>\n      <td>publishing</td>\n      <td>4250.0</td>\n      <td>4718.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>17.0</td>\n      <td>5770.03</td>\n      <td>40</td>\n      <td>zines</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3721</td>\n      <td>0</td>\n      <td>publishing</td>\n      <td>5000.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>22.0</td>\n      <td>3804.70</td>\n      <td>30</td>\n      <td>zines</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3751</td>\n      <td>1</td>\n      <td>publishing</td>\n      <td>1500.0</td>\n      <td>25.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20.0</td>\n      <td>1705.15</td>\n      <td>30</td>\n      <td>zines</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3798</td>\n      <td>2</td>\n      <td>publishing</td>\n      <td>4000.0</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>19.0</td>\n      <td>5371.42</td>\n      <td>60</td>\n      <td>zines</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3863</td>\n      <td>0</td>\n      <td>publishing</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16.0</td>\n      <td>9.15</td>\n      <td>30</td>\n      <td>zines</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df = pd.read_csv('KickstarterCleanedv4.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0','goal','spotlight'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['backers_count', 'category', 'pledged', 'state', 'blurb_length',\n",
       "       'goal_in_usd', 'campaign_duration', 'sub_category'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8317, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Kickstarter_FinalCleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8317, 7)\n(8317,)\n"
     ]
    }
   ],
   "source": [
    "# Extracting the target and feature matrix\n",
    "target = 'state'\n",
    "y = df[target]\n",
    "X = df.drop(columns=target)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4990, 7) (3327, 7)\n(4990,) (3327,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .4)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "baseline accuracy 0.6059877359624865\n"
     ]
    }
   ],
   "source": [
    "#Baseline\n",
    "\n",
    "print('baseline accuracy', y.value_counts(normalize=True).max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Random Forest\n",
    "\n",
    "model_rf = make_pipeline(OrdinalEncoder(),\n",
    "                       SimpleImputer(strategy=\"mean\"),\n",
    "                       RandomForestClassifier( n_jobs=-1, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "model_dt = make_pipeline(OrdinalEncoder(),\n",
    "                      SimpleImputer(strategy=\"mean\"),\n",
    "                      DecisionTreeClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "model_xgb = make_pipeline(OrdinalEncoder(),\n",
    "                       SimpleImputer(strategy=\"mean\"),\n",
    "                       XGBClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boost\n",
    "\n",
    "model_gb = make_pipeline(OrdinalEncoder(),\n",
    "                       SimpleImputer(strategy=\"mean\"),\n",
    "                       GradientBoostingClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/rhia/.local/share/virtualenvs/KickstarterSuccess-Diw2u4NI/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "/home/rhia/.local/share/virtualenvs/KickstarterSuccess-Diw2u4NI/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "/home/rhia/.local/share/virtualenvs/KickstarterSuccess-Diw2u4NI/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[11:25:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['category', 'sub_category'],\n",
       "                                mapping=[{'col': 'category',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': fashion          1\n",
       "technology       2\n",
       "film & video     3\n",
       "art              4\n",
       "food             5\n",
       "design           6\n",
       "publishing       7\n",
       "theater          8\n",
       "dance            9\n",
       "comics          10\n",
       "music           11\n",
       "crafts          12\n",
       "photography     13\n",
       "NaN             -2\n",
       "dtype: int64},\n",
       "                                         {'col': 'sub_category',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': footwear               1\n",
       "robots                 2\n",
       "thrillers              3\n",
       "social practice        4\n",
       "community gardens      5\n",
       "                    ... \n",
       "restaurants          119\n",
       "translations         120\n",
       "literary journals    121\n",
       "letterpress          122\n",
       "NaN                   -2\n",
       "Length: 123, dtype: int64}])),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('gradientboostingclassifier',\n",
       "                 GradientBoostingClassifier(random_state=42))])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "model_rf.fit(X_train,y_train)\n",
    "model_dt.fit(X_train,y_train)\n",
    "model_xgb.fit(X_train,y_train)\n",
    "model_gb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model_dt accuracy score 1.0\n",
      "model_rf accuracy score 0.9997995991983968\n",
      "model_xgb accuracy score 1.0\n",
      "model_gb accuracy score 0.9849699398797596\n",
      "/home/rhia/.local/share/virtualenvs/KickstarterSuccess-Diw2u4NI/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Check Metrics on training\n",
    "print('model_dt accuracy score', accuracy_score(y_train, model_dt.predict(X_train)))\n",
    "print('model_rf accuracy score', accuracy_score(y_train, model_rf.predict(X_train)))\n",
    "print('model_xgb accuracy score', accuracy_score(y_train, model_xgb.predict(X_train)))\n",
    "print('model_gb accuracy score', accuracy_score(y_train, model_gb.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model_dt accuracy score 0.9690411782386534\n",
      "model_rf accuracy score 0.974150886684701\n",
      "model_xgb accuracy score 0.9846708746618575\n",
      "model_gb accuracy score 0.9774571686203787\n",
      "/home/rhia/.local/share/virtualenvs/KickstarterSuccess-Diw2u4NI/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Metrics with test data\n",
    "# print('model_dt accuracy score', accuracy_score(y_test, model_dt.predict(X_test)))\n",
    "# print('model_rf accuracy score', accuracy_score(y_test, model_rf.predict(X_test)))\n",
    "# print('model_xgb accuracy score', accuracy_score(y_test, model_xgb.predict(X_test)))\n",
    "# print('model_gb accuracy score', accuracy_score(y_test, model_gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models using pickle\n",
    "saved_model_rf = pickle.dumps(model_rf)\n",
    "saved_model_xgb = pickle.dumps(model_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['assets/model_rf']"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "\n",
    "joblib_file = \"joblib_RF_Model.pkl\"  \n",
    "joblib.dump(model_rf, 'assets/model_rf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['assets/model_xgb']"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "joblib_file = \"joblib_XGB_Model.pkl\"  \n",
    "joblib.dump(model_xgb, 'assets/model_xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['category', 'sub_category'],\n",
       "                                mapping=[{'col': 'category',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': fashion          1\n",
       "technology       2\n",
       "film & video     3\n",
       "art              4\n",
       "food             5\n",
       "design           6\n",
       "publishing       7\n",
       "theater          8\n",
       "dance            9\n",
       "comics          10\n",
       "music           11\n",
       "crafts          12\n",
       "photography     13\n",
       "NaN             -2\n",
       "dtype: int64},\n",
       "                                         {'col': 'sub_category',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': footwear               1\n",
       "robots                 2\n",
       "thrillers              3\n",
       "so...\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=1, random_state=42,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "#Testing if model saved and working correctly\n",
    "# # Load from file\n",
    "# load_xgb_model = joblib.load('assets/model_xgb')\n",
    "# load_xgb_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score: 98.47 %\n",
      "/home/rhia/.local/share/virtualenvs/KickstarterSuccess-Diw2u4NI/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/rhia/.local/share/virtualenvs/KickstarterSuccess-Diw2u4NI/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "# # Use the Reloaded Joblib Model to \n",
    "# # Calculate the accuracy score and predict target values\n",
    "\n",
    "# # Calculate the Score \n",
    "# score = load_xgb_model.score(X_test, y_test)  \n",
    "# # Print the Score\n",
    "# print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
    "\n",
    "# # Predict the Labels using the reloaded Model\n",
    "# Ypredict = load_xgb_model.predict(X_test)  \n",
    "\n",
    "# Ypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}